{"cells":[{"cell_type":"markdown","metadata":{"id":"b8MO4w7-BklO"},"source":["# Importing packages and datasets."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":257,"status":"ok","timestamp":1694601073998,"user":{"displayName":"Tarun Krishnan","userId":"04307794948231036457"},"user_tz":-600},"id":"UznGqZzuBjJC"},"outputs":[],"source":["import pandas\n","import numpy\n","import pickle\n","\n","import altair\n","\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.neural_network import MLPRegressor\n","\n","from sklearn.metrics import mean_squared_error\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["dataset_file_path = \"../data/processed/\"\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1068,"status":"ok","timestamp":1694600453886,"user":{"displayName":"Tarun Krishnan","userId":"04307794948231036457"},"user_tz":-600},"id":"h2byloZCBuiY","outputId":"3bc03578-78b1-4608-919f-6bb393cf0714"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2895, 30)\n"]}],"source":["dataFrame = pandas.read_csv(dataset_file_path + \"cleaned.csv\")\n","print(dataFrame.shape)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316,"status":"ok","timestamp":1694601874932,"user":{"displayName":"Tarun Krishnan","userId":"04307794948231036457"},"user_tz":-600},"id":"8FvRPv4BGurv","outputId":"fc18e787-b8e4-4d99-8349-bed7908b6d95"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2895, 30)\n"]}],"source":["normalisedDataFrame = pandas.read_csv(dataset_file_path + \"normalised.csv\")\n","print(normalisedDataFrame.shape)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1694601617113,"user":{"displayName":"Tarun Krishnan","userId":"04307794948231036457"},"user_tz":-600},"id":"B6Vu9IFgDxGt","outputId":"8b28a6e3-de11-49f9-8042-fc85d7e9b55a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['avgAnnCount', 'avgDeathsPerYear', 'TARGET_deathRate', 'incidenceRate',\n","       'medIncome', 'popEst2015', 'povertyPercent', 'studyPerCap', 'MedianAge',\n","       'MedianAgeMale', 'MedianAgeFemale', 'AvgHouseholdSize',\n","       'PercentMarried', 'PctNoHS18_24', 'PctHS18_24', 'PctBachDeg18_24',\n","       'PctHS25_Over', 'PctBachDeg25_Over', 'PctEmployed16_Over',\n","       'PctUnemployed16_Over', 'PctPrivateCoverage', 'PctEmpPrivCoverage',\n","       'PctPublicCoverage', 'PctPublicCoverageAlone', 'PctWhite', 'PctBlack',\n","       'PctAsian', 'PctOtherRace', 'PctMarriedHouseholds', 'BirthRate'],\n","      dtype='object')\n"]}],"source":["print(dataFrame.columns)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":372,"status":"ok","timestamp":1694600577542,"user":{"displayName":"Tarun Krishnan","userId":"04307794948231036457"},"user_tz":-600},"id":"BIjAnODgB77t"},"outputs":[],"source":["possibly_related_fields = [\n","                           \"medIncome\", \"povertyPercent\", \"PctUnemployed16_Over\", \"PctEmployed16_Over\",\n","                           \"PctHS25_Over\", \"PctBachDeg25_Over\",\n","                           \"PctPrivateCoverage\", \"PctEmpPrivCoverage\", \"PctPublicCoverage\", \"PctPublicCoverageAlone\",\n","                           \"PctMarriedHouseholds\", \"PercentMarried\"\n","                           ]\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1694601628294,"user":{"displayName":"Tarun Krishnan","userId":"04307794948231036457"},"user_tz":-600},"id":"z78m9A9bBwmo","outputId":"e81384ae-5c64-4212-bb05-d4211cfba840"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2395, 12) \t (500, 12)\n","(2395,) \t (500,)\n"]}],"source":["X = dataFrame[possibly_related_fields + [\"TARGET_deathRate\"]].copy()\n","y = X.pop(\"TARGET_deathRate\")\n","\n","train, test = train_test_split(dataFrame, test_size=0.1727, random_state=42)\n","df_train, df_test = train_test_split(X, test_size=0.1727, random_state=42)\n","y_train, y_test = train_test_split(y, test_size=0.1727, random_state=42)\n","\n","print(df_train.shape, \"\\t\", df_test.shape)\n","print(y_train.shape, \"\\t\", y_test.shape)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1694601919928,"user":{"displayName":"Tarun Krishnan","userId":"04307794948231036457"},"user_tz":-600},"id":"Bq7O-LQpHS2U","outputId":"ccebb510-ad71-42d0-d4b4-cbc235267d41"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2395, 12) \t (500, 12)\n","(2395,) \t (500,)\n"]}],"source":["X = normalisedDataFrame[possibly_related_fields + [\"TARGET_deathRate\"]].copy()\n","y = X.pop(\"TARGET_deathRate\")\n","\n","train, test = train_test_split(dataFrame, test_size=0.1727, random_state=42)\n","df_train, df_test = train_test_split(X, test_size=0.1727, random_state=42)\n","y_train, y_test = train_test_split(y, test_size=0.1727, random_state=42)\n","\n","print(df_train.shape, \"\\t\", df_test.shape)\n","print(y_train.shape, \"\\t\", y_test.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"SJvCrXorB-YN"},"source":["# Baseline Performance."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1694601923174,"user":{"displayName":"Tarun Krishnan","userId":"04307794948231036457"},"user_tz":-600},"id":"nNIngxn-B9rZ","outputId":"b03a9d0a-97b5-49b0-f9c1-ab23644c78ca"},"outputs":[{"data":{"text/plain":["712.9935696334397"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["y_mean = y.mean()\n","\n","y_base = numpy.full((y_test.shape[0], ), y_mean)\n","(y_base - y_test).sum()\n","\n","mean_squared_error(y_test, y_base, squared=True)\n"]},{"cell_type":"markdown","metadata":{"id":"rchu0lWxEWIt"},"source":["# Training."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 11401.77746125\n","Iteration 2, loss = 5537.97522267\n","Iteration 3, loss = 1954.92108287\n","Iteration 4, loss = 609.58634325\n","Iteration 5, loss = 535.91158588\n","Iteration 6, loss = 493.83980065\n","Iteration 7, loss = 452.59503237\n","Iteration 8, loss = 438.58544007\n","Iteration 9, loss = 420.56796724\n","Iteration 10, loss = 403.96876960\n","Iteration 11, loss = 388.45926111\n","Iteration 12, loss = 373.88485411\n","Iteration 13, loss = 360.02650462\n","Iteration 14, loss = 346.61129164\n","Iteration 15, loss = 332.92492242\n","Iteration 16, loss = 321.23640847\n","Iteration 17, loss = 311.52528663\n","Iteration 18, loss = 304.30659641\n","Iteration 19, loss = 298.57235602\n","Iteration 20, loss = 294.49845291\n","Iteration 21, loss = 291.39065495\n","Iteration 22, loss = 289.05474686\n","Iteration 23, loss = 287.14000985\n","Iteration 24, loss = 285.55188283\n","Iteration 25, loss = 284.11210721\n","Iteration 26, loss = 282.82425584\n","Iteration 27, loss = 281.61481501\n","Iteration 28, loss = 280.47316325\n","Iteration 29, loss = 279.38223496\n","Iteration 30, loss = 278.34546066\n","Iteration 31, loss = 277.36098217\n","Iteration 32, loss = 276.40715895\n","Iteration 33, loss = 275.59664286\n","Iteration 34, loss = 274.68990051\n","Iteration 35, loss = 273.81303940\n","Iteration 36, loss = 273.03127419\n","Iteration 37, loss = 272.21447402\n","Iteration 38, loss = 271.46572126\n","Iteration 39, loss = 270.72125690\n","Iteration 40, loss = 270.02419282\n","Iteration 41, loss = 269.35017187\n","Iteration 42, loss = 268.72420832\n","Iteration 43, loss = 268.12255963\n","Iteration 44, loss = 267.56006449\n","Iteration 45, loss = 267.03557730\n","Iteration 46, loss = 266.53478251\n","Iteration 47, loss = 266.07290411\n","Iteration 48, loss = 265.63252527\n","Iteration 49, loss = 265.23104093\n","Iteration 50, loss = 264.84392955\n","Iteration 51, loss = 264.48631554\n","Iteration 52, loss = 264.15917487\n","Iteration 53, loss = 263.84166830\n","Iteration 54, loss = 263.54304950\n","Iteration 55, loss = 263.27144778\n","Iteration 56, loss = 263.01177755\n","Iteration 57, loss = 262.76451286\n","Iteration 58, loss = 262.55456825\n","Iteration 59, loss = 262.36396007\n","Iteration 60, loss = 262.08751474\n","Iteration 61, loss = 261.90118167\n","Iteration 62, loss = 261.68499892\n","Iteration 63, loss = 261.48292561\n","Iteration 64, loss = 261.29897446\n","Iteration 65, loss = 261.10806920\n","Iteration 66, loss = 260.92775423\n","Iteration 67, loss = 260.75966285\n","Iteration 68, loss = 260.59845163\n","Iteration 69, loss = 260.43568944\n","Iteration 70, loss = 260.28424070\n","Iteration 71, loss = 260.13209694\n","Iteration 72, loss = 259.98375860\n","Iteration 73, loss = 259.85742941\n","Iteration 74, loss = 259.72568828\n","Iteration 75, loss = 259.60704400\n","Iteration 76, loss = 259.50079870\n","Iteration 77, loss = 259.39376156\n","Iteration 78, loss = 259.28937556\n","Iteration 79, loss = 259.19482965\n","Iteration 80, loss = 259.10276721\n","Iteration 81, loss = 258.99944183\n","Iteration 82, loss = 258.90272985\n","Iteration 83, loss = 258.81916433\n","Iteration 84, loss = 258.72296042\n","Iteration 85, loss = 258.62597314\n","Iteration 86, loss = 258.55077666\n","Iteration 87, loss = 258.44624230\n","Iteration 88, loss = 258.35182005\n","Iteration 89, loss = 258.26427577\n","Iteration 90, loss = 258.18198876\n","Iteration 91, loss = 258.09311738\n","Iteration 92, loss = 257.99746848\n","Iteration 93, loss = 257.90011422\n","Iteration 94, loss = 257.81557878\n","Iteration 95, loss = 257.72935264\n","Iteration 96, loss = 257.61498316\n","Iteration 97, loss = 257.50107291\n","Iteration 98, loss = 257.37517219\n","Iteration 99, loss = 257.25918272\n","Iteration 100, loss = 257.12934493\n","Iteration 101, loss = 257.00532788\n","Iteration 102, loss = 256.87616615\n","Iteration 103, loss = 256.76536783\n","Iteration 104, loss = 256.65427891\n","Iteration 105, loss = 256.56536211\n","Iteration 106, loss = 256.45943228\n","Iteration 107, loss = 256.36014233\n","Iteration 108, loss = 256.26412710\n","Iteration 109, loss = 256.16900633\n","Iteration 110, loss = 256.06989490\n","Iteration 111, loss = 255.97883959\n","Iteration 112, loss = 255.88431969\n","Iteration 113, loss = 255.79436269\n","Iteration 114, loss = 255.69553201\n","Iteration 115, loss = 255.58661134\n","Iteration 116, loss = 255.50218629\n","Iteration 117, loss = 255.40414039\n","Iteration 118, loss = 255.29805160\n","Iteration 119, loss = 255.20043453\n","Iteration 120, loss = 255.10730012\n","Iteration 121, loss = 255.00278572\n","Iteration 122, loss = 254.90037056\n","Iteration 123, loss = 254.81222716\n","Iteration 124, loss = 254.69779865\n","Iteration 125, loss = 254.58919012\n","Iteration 126, loss = 254.51563526\n","Iteration 127, loss = 254.40579620\n","Iteration 128, loss = 254.30537944\n","Iteration 129, loss = 254.21622729\n","Iteration 130, loss = 254.11516636\n","Iteration 131, loss = 254.02515127\n","Iteration 132, loss = 253.92451004\n","Iteration 133, loss = 253.81878437\n","Iteration 134, loss = 253.74246857\n","Iteration 135, loss = 253.63698540\n","Iteration 136, loss = 253.54024402\n","Iteration 137, loss = 253.45218839\n","Iteration 138, loss = 253.35250247\n","Iteration 139, loss = 253.25642369\n","Iteration 140, loss = 253.15972112\n","Iteration 141, loss = 253.07029134\n","Iteration 142, loss = 252.97788537\n","Iteration 143, loss = 252.87882213\n","Iteration 144, loss = 252.79554842\n","Iteration 145, loss = 252.70018121\n","Iteration 146, loss = 252.60226457\n","Iteration 147, loss = 252.52247706\n","Iteration 148, loss = 252.42419679\n","Iteration 149, loss = 252.32362010\n","Iteration 150, loss = 252.23376488\n","Iteration 151, loss = 252.14325615\n","Iteration 152, loss = 252.03627867\n","Iteration 153, loss = 251.94456976\n","Iteration 154, loss = 251.86444406\n","Iteration 155, loss = 251.75840959\n","Iteration 156, loss = 251.67144913\n","Iteration 157, loss = 251.59166129\n","Iteration 158, loss = 251.48919977\n","Iteration 159, loss = 251.40056457\n","Iteration 160, loss = 251.32148489\n","Iteration 161, loss = 251.22835962\n","Iteration 162, loss = 251.13572224\n","Iteration 163, loss = 251.04878452\n","Iteration 164, loss = 250.95590937\n","Iteration 165, loss = 250.86038879\n","Iteration 166, loss = 250.78059765\n","Iteration 167, loss = 250.69847933\n","Iteration 168, loss = 250.60318120\n","Iteration 169, loss = 250.51558713\n","Iteration 170, loss = 250.43561257\n","Iteration 171, loss = 250.33943134\n","Iteration 172, loss = 250.25912688\n","Iteration 173, loss = 250.17705797\n","Iteration 174, loss = 250.09550940\n","Iteration 175, loss = 250.01425851\n","Iteration 176, loss = 249.92230900\n","Iteration 177, loss = 249.84866923\n","Iteration 178, loss = 249.75786506\n","Iteration 179, loss = 249.67108136\n","Iteration 180, loss = 249.59348427\n","Iteration 181, loss = 249.50967974\n","Iteration 182, loss = 249.41858181\n","Iteration 183, loss = 249.34823831\n","Iteration 184, loss = 249.28178576\n","Iteration 185, loss = 249.18527412\n","Iteration 186, loss = 249.11013746\n","Iteration 187, loss = 249.03522498\n","Iteration 188, loss = 248.95616501\n","Iteration 189, loss = 248.87935634\n","Iteration 190, loss = 248.80115322\n","Iteration 191, loss = 248.71279203\n","Iteration 192, loss = 248.64471667\n","Iteration 193, loss = 248.56814735\n","Iteration 194, loss = 248.49882251\n","Iteration 195, loss = 248.41839514\n","Iteration 196, loss = 248.33724096\n","Iteration 197, loss = 248.27312822\n","Iteration 198, loss = 248.19609718\n","Iteration 199, loss = 248.12025587\n","Iteration 200, loss = 248.04897395\n"]},{"name":"stderr","output_type":"stream","text":["/home/ubuntu/Workspaces/DataScienceProjects/regression/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["nnRegressor = neuralNetwork = MLPRegressor(\n","\t\thidden_layer_sizes=[128], \t\t\t\t#array-like of shape(n_layers - 2,), default=(100,)\n","\t\tbatch_size=\"auto\", \t\t\t\t\t\t#int, default=’auto’\n","\t\tactivation=\"relu\", \t\t\t\t\t\t#{’identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’\n","\t\tsolver=\"adam\", \t\t\t\t\t\t\t#{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’\n","\t\talpha=0.0001,\t\t\t\t\t\t\t#float, default=0.0001\n","\t\tlearning_rate =\"constant\", \t\t\t\t#{‘constant’, ‘invscaling’, ‘adaptive’}, default=’constant’\n","\t\tlearning_rate_init = 0.001,\t\t\t\t#float, default=0.001\n","\t\tpower_t=0.5,\t\t\t\t\t\t\t#float, default=0.5\n","\t\tmax_iter=200,\t\t\t\t\t\t\t#int, default=200\n","\t\tshuffle=False,\t\t\t\t\t\t\t#bool, default=True, used when solver=’sgd’ or ‘adam’\n","\t\trandom_state=1,\n","\t\ttol=1e-4,\t\t\t\t\t\t\t\t#float, default=1e-4\n","\t\tverbose=True\t\t\t\t\t\t\t#bool, default=False\n",")\n","\n","regression = nnRegressor.fit(df_train, y_train)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model_file_path = \"../models/\"\n","model_file_name = \"neural_network.pickle\"\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["pickle.dump(regression, open(model_file_path + model_file_name, \"wb\"))\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["regression = pickle.load(open(model_file_path + model_file_name, \"rb\"))\n"]},{"cell_type":"markdown","metadata":{},"source":["# Testing."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def results(test_type):\n","\n","\tmse = 0.0\n","\tprediction_line = altair.Chart()\n","\tactual_line = altair.Chart()\n","\n","\tif test_type == \"test\":\n","\t\ty_preds = neuralNetwork.predict(df_test)\n","\t\tprediction_line = altair.Chart(pandas.DataFrame({'x': y_test, 'y': y_preds})).mark_line(color='blue').encode(\n","      \t\tx='x',\n","      \t\ty='y'\n","    \t)\n","\t\tactual_line = altair.Chart(pandas.DataFrame({'x': y_test, 'y': y_test})).mark_line(color='orange').encode(\n","      \t\tx='x',\n","      \t\ty='y'\n","    \t)\n","\t\tmse = mean_squared_error(y_test, y_preds, squared=True)\n","\n","\telif test_type == \"train\":\n","\t\ty_preds = neuralNetwork.predict(df_train)\n","\t\tprediction_line = altair.Chart(pandas.DataFrame({'x': y_train, 'y': y_preds})).mark_line(color='blue').encode(\n","      \t\tx='x',\n","      \t\ty='y'\n","    \t)\n","\t\tactual_line = altair.Chart(pandas.DataFrame({'x': y_train, 'y': y_train})).mark_line(color='orange').encode(\n","      \t\tx='x',\n","      \t\ty='y'\n","    \t)\n","\t\tmse = mean_squared_error(y_train, y_preds, squared=True)\n","\n","\treturn (actual_line, prediction_line, mse)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["493.42380849040933\n"]}],"source":["actual_line, prediction_line, mse = results(\"train\")\n","print(mse)\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["448.441232003191\n"]}],"source":["actual_line, prediction_line, mse = results(\"test\")\n","print(mse)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNl7ME/mDG8L1oEwUvLpuIk","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
